{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Conditional_SeqGAN - 24.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj8t5D6dxrFI"
      },
      "source": [
        "# Conditional SeqGAN - 24\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQS72HbTJzv5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmXk132iBXMt"
      },
      "source": [
        "! /opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPO1wL2Vx1KL"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/ConditionalSeqGAN\"\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9TIvRKVt7b9"
      },
      "source": [
        "import seed\n",
        "\n",
        "from gen_opts import gen_opts\n",
        "from gen_dataset import gen_dataset\n",
        "from gen_dataloader import get_gen_iter\n",
        "\n",
        "from encoder_decoder import encoder\n",
        "from encoder_decoder import decoder\n",
        "from generator import generator\n",
        "\n",
        "from gen_optimizer import encoder_optim, decoder_optim, encoder_optim_scheduler, decoder_optim_scheduler\n",
        "from gen_train_epoch import train_gen\n",
        "\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bCz1_wytmCj"
      },
      "source": [
        "def load_checkpoint(checkpoint_PATH, encoder, decoder, encoder_optim, decoder_optim):\n",
        "    if checkpoint_PATH != None:\n",
        "        model_CKPT = torch.load(checkpoint_PATH)\n",
        "        encoder.load_state_dict(model_CKPT['encoder_state_dict'])\n",
        "        decoder.load_state_dict(model_CKPT['decoder_state_dict'])\n",
        "        encoder_optim.load_state_dict(model_CKPT['encoder_optim_state_dict'])\n",
        "        decoder_optim.load_state_dict(model_CKPT['decoder_optim_state_dict'])\n",
        "    return encoder, decoder, encoder_optim, decoder_optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3bvopSUtnPt"
      },
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/ConditionalSeqGAN/checkpoints/generator/A Deep Reinforced Generative Adversarial Network for Abstractive Text Summarization_2020-12-04 18:58:07_epoch_1_iter_3800_loss_0.17_step_100.pt'\n",
        "encoder, decoder, encoder_optim, decoder_optim = load_checkpoint(checkpoint_path, encoder, decoder, encoder_optim, decoder_optim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK_9Cy2LFuoc"
      },
      "source": [
        "## Generator Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkfcl8VCa6DC"
      },
      "source": [
        "gen_iter = get_gen_iter(gen_dataset=gen_dataset, batch_size=gen_opts.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm78OcojJR_x"
      },
      "source": [
        "# if colab terminate the code then restart from here.\n",
        "continue_point = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHV0ouR1FB-x"
      },
      "source": [
        "train_gen(dataset = gen_dataset, encoder = encoder, decoder = decoder, encoder_optim = encoder_optim, decoder_optim = decoder_optim, encoder_optim_scheduler = encoder_optim_scheduler, decoder_optim_scheduler = decoder_optim_scheduler, num_epochs = gen_opts.num_epochs, gen_iter = gen_iter, save_every_step = gen_opts.save_every_step, print_every_step = gen_opts.print_every_step, continue_point = continue_point) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUGwWnozFq39"
      },
      "source": [
        "## Discriminator Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvGIiumdDiup"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/ConditionalSeqGAN\"\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9pqq9Yw_2EH"
      },
      "source": [
        "from gen_dataset import gen_dataset\n",
        "\n",
        "from dis_opts import dis_opts\n",
        "from discriminator import discriminator\n",
        "from write_dis_dataset import get_training_pairs\n",
        "from dis_dataloader import get_dis_iter\n",
        "from dis_train_epoch import train_dis\n",
        "from dis_optimizer import dis_optim\n",
        "\n",
        "import torch\n",
        "import seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BqjhrVoFLm-"
      },
      "source": [
        "training_pairs = get_training_pairs(gen_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNW1u0bhD79R"
      },
      "source": [
        "dis_iter = get_dis_iter(training_pairs=training_pairs, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HZrJ7dSFOKg"
      },
      "source": [
        "train_dis(discriminator=discriminator, \n",
        "          dis_optim=dis_optim, \n",
        "          num_epochs=dis_opts.num_epochs, \n",
        "          dis_iter=dis_iter, \n",
        "          save_every_step=dis_opts.save_every_step, \n",
        "          print_every_step=dis_opts.print_every_step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuQMLygeFlWz"
      },
      "source": [
        "## Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGUyQr1KDj4c"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/ConditionalSeqGAN\"\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxwGpuyxDQIX"
      },
      "source": [
        "from GAN_opts import GAN_opts\n",
        "from adversarial_train_epoch import train_adversarial\n",
        "import seed\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DYtVbd-FQ80"
      },
      "source": [
        "gen_iter = get_gen_iter(gen_dataset=gen_dataset,\n",
        "                        batch_size=GAN_opts.batch_size,\n",
        "                        num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmXICH9DFWYJ"
      },
      "source": [
        "train_adversarial(dataset=gen_dataset, #\n",
        "                  generator=generator,\n",
        "                  discriminator=discriminator,\n",
        "                  encoder_optim=encoder_optim,\n",
        "                  decoder_optim=decoder_optim,\n",
        "                  dis_optim=dis_optim, \n",
        "                  gen_iter=gen_iter,\n",
        "                  gen_dataset=gen_dataset,\n",
        "                  num_epochs=1, \n",
        "                  print_every_step=GAN_opts.G_print_every_step, \n",
        "                  save_every_step=GAN_opts.G_save_every_step,\n",
        "                  num_rollout=GAN_opts.num_rollout)\n",
        "\n",
        "print(\"Finished!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}